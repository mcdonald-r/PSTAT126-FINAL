---
title: "PSTAT126-Final-V2"
output:
  pdf_document: default
  html_document:
    df_print: paged
date: "2024-06-07"
---

## PART - 1 Data Description and Descriptive Statistics

```{r Part 1.0, echo = T, results = T}
Diamond_dataset <- read.csv("/users/robeh/desktop/DiamondsPrices2022.csv")
attach(Diamond_dataset)
head(Diamond_dataset)

library(dplyr)
set.seed(1)
diamonds_sample <- sample_n(Diamond_dataset, 500)

library(skimr)
# Have to use this instead of skim, because I get error trying to load the histogram 
# due to a latex error
skim_without_charts(diamonds_sample)
```

### Description of Variables and Observational Unit 

Main Variables Being Testing:

The **Color** variable is a color grading scale that ranges from D to H (in the data set) and rates the colorless or
near colorless of a white diamond. Diamonds in the ranges of D to F are the best that contain no other color and are
of the highest quality. Diamonds in the ranges of G to J are still high quality but contain slight traces of color.

The **Clarity** variable rates the presence of internal or external blemishes, known as inclusions within the
diamond. In the data set the ratings go from VVS2, VS1, VS2, SI1, SI2. VVS2 means that inclusions are very difficult
to see under 10x magnification. VS means that inclusions are difficult to see under 10x magnification. VS2 means
that inclusions are somewhat easier to see under 10x magnification, but still minor. SI1 means that inclusions are
noticeable under 10x magnification. SI2 means that inclusions are more easily noticeable under 10x magnification.

The **Price** variable determines the monetary value of a diamond. There are a lot of factors that go into
determining the value of a diamond like cut, clarity, color, shape, and many more. 

The **Table** of a diamond refers to the large flat face when looking down at the top of the diamond. In the data
set the variable is a percentage of how big the table is compared to the total diameter of the diamond.

The **Depth** of a diamond is the distance from the large flat surface of the top of the diamond, known as the
table, to the bottom of the diamond, known as the culet. In the data set the variable is a percentage of how deep a
diamond in relation to its width. 

The **Observational Unit** of the data set is a single diamond out of the total 54,000 diamonds that make up the data
set. Each contain the variables stated before as well as 6 other variables that are outside the scope of this
project.

Other Variables in The Data Set:

The **Carat** refers to the weight unit that measures gemstones, in this case it is measuring diamonds. One carat is 
equal to 200 milligrams.

The **Cut** variable is a categorical variable is a rating that is an important piece of the puzzle that determines how
good the diamond is overall. It goes into how the diamond looks visually as well as how well the diamond is crafted.

The **X**, **Y**, and **Z** variable just refers to the dimensions of the diamond. The **x** is the length in mm, the 
**y** is the width in mm, and the **z** is the depth in mm. 

```{r Part 1.2, echo = T, results = T}
fit0 <- lm(price ~ table + clarity, data = diamonds_sample)
summary(fit0)
```

From the results we can see the the variables clarity and table don't have a significant effect on the price variable.
When looking at the R-Squared value, we see that they only account for 6.14% of the variance in price. 

```{r Part 1.3, echo = T, results = T}
table(diamonds_sample$color)

diamonds_sample$D = ifelse(diamonds_sample$color == "D", 1, 0)
diamonds_sample$E = ifelse(diamonds_sample$color == "E", 1, 0)
diamonds_sample$F = ifelse(diamonds_sample$color == "F", 1, 0)
diamonds_sample$G = ifelse(diamonds_sample$color == "G", 1, 0)
diamonds_sample$H = ifelse(diamonds_sample$color == "H", 1, 0)
diamonds_sample$I = ifelse(diamonds_sample$color == "I", 1, 0)
diamonds_sample$J = ifelse(diamonds_sample$color == "J", 1, 0)
attach(diamonds_sample)

fit2 <- lm(price ~ depth + E + F + G + H + I + J, data = diamonds_sample)
summary(fit2)
```

Now looking at depth and color (using dummy variables) we can see how alike the last test they have a very small 
significance on price. Back to the R-Squared value it shows that they only account for 7.47% of the variance in 
the price variable.

```{r Part1.4, echo = T, results = T}
fit3 <- lm(price ~ color + clarity + depth + table, data = diamonds_sample)
summary(fit3)
```

Constructing a model with all the variables that I randomly chose, it is apparent that the ones I chose don't have that
big of an impact when it comes to the effect of the price. In the last summary, it does show a lot of significance stars
but in the end the R-Squared value only comes out to 0.1434, something I'll have to work on from here on out on this 
project. 

### Comments on Part 1

I was surprised that the variables I choose to test showed that they didn't have that big an effect on the overall
price of the diamond. The variables I chose had a very low R-Squared value which I wasn't really expected. However, 
after looking at the data again I realized that the percentages of the depth and table don't can't really quantify the 
diamond. They give a percentage of the proportion, but diamond that are way different in size could still have the same
depth or table, so it makes sense that these values don't really have a big affect on the price. 

## PART - 2 Simple Linear Regression

```{r Part 2, echo = T, results = T}
SLR <- lm(price ~ table, data = diamonds_sample)
par(mfrow=c(2,2))
plot(SLR)

summary(SLR)

confint(SLR)

par(mfrow=c(1,1))
plot(diamonds_sample$table, diamonds_sample$price, 
     main = "Price vs Table Percentage",
     xlab = "Table Percentage", ylab = "Price")

abline(SLR, col = "red", lwd = 2)
```

From the plot of this simple linear model between the price and the table we can start by looking at the Residuals vs. Fitted
and see that there really isn't a pattern that emerges here. The points have a lot of fluctuation and many are very far away
from zero showing that the prediction values aren't very significant. 

When it comes to the Q-Q Residuals, the start of the graph doesn't look all too bad. The points form around that straight 
line from the beginning, but a little halfway through that line the points take a steep upturn and don't return back to the 
straight line visually showing that the residuals aren't normally distributed as the quantiles increase. 

The Scale Location graph goes along with the trend of proving that our two variables aren't significant to each other. This
part of the plot doesn't show the points forming a funnel shape that would suggest constant variance among the residuals,
instead the points are scattered everywhere.

Lastly in the Residuals vs. Leverage, we see a decent amount of outliers that have a high leverage although they don't have 
high residuals, as the residuals go up the leverage trends to go down for these outliers. Still these outliers show that
there can be an effect on our model because of them. 

Now looking at the summary statistics, the table is coming to the same conclusion. We see that the p-values are very high
and doesn't push is towards the idea of a significant affect. Moving onto the R-Squared value, we see that it is at an
extremely low value of 0.006786, or that table accounts for 0.68% of the variance of the price. 

Moving onto the confidence interval, we can see how the intercept and table both include 0 within the interval, proving that 
the parameters aren't significant. The large range at which the values can be from also show the little significance if any
that the parameters have on each other.

Lastly, the graph of the price vs table with the plotted regression line is a clear visual that they have little to no 
relationship. The graph shows how the points do not end up along the line at all and many are scattered around from outliers 
as there isn't a clear pattern in their grouping. 

```{r Part 2.1, echo = T, results = T}
SLR2 <- lm(log(price) ~ table, data = diamonds_sample)
par(mfrow=c(2,2))
plot(SLR2)
summary(SLR2)

SLR3 <- lm(price ~ log(table), data = diamonds_sample)
par(mfrow=c(2,2))
plot(SLR3)
summary(SLR3)
```

After testing the initial hypothesis it was apparent the the variables I was using didn't have much correlation between the
two of them. To try and make the model better, I experimented with using the log function on the y and x variables of the 
model. As you can see I started with the log on the y or the price and made a difference by getting the R-Squared value to 
0.01504. Although this is extremely low, within the scope of this test I more than doubled the original R-Squared value. 
After this, I tried to switch the log function onto the x variable, however it didn't have a R-Squared value nearly as good
as my first transformation so I left the log on the price variable.

``` {r Part 2.2, echo = FALSE, results = 'hide'}
# R-Squared 0.8463
# test_model_1 <- lm(log(price) ~ table + x, data = diamonds_sample)
# summary(test_model_1)

# Not as much significance as test_model_1, R-Square 0.8462
# test_model_2 <- lm(log(price) ~ table + y, data = diamonds_sample)
# summary(test_model_2)

# Not as much significance as test_model_1 and test_model_2, R-Squared 0.7883
# test_model_3 <- lm(log(price) ~ table + z, data = diamonds_sample)
# summary(test_model_3)

# Best model with 3 variables at R_Squared of 0.8696
# test_model_4 <- lm(log(price) ~ table + x + clarity, data = diamonds_sample)
# summary(test_model_4)

# Didn't make cut 
# test_model_5 <- lm(log(price) ~ table + x + carat, data = diamonds_sample)
# summary(test_model_5)

# Didn't make cut 
# test_model_6 <- lm(log(price) ~ table + x + depth, data = diamonds_sample)
# summary(test_model_6)

# Had a R-Squared value of 0.8697, but included another variable
# test_model_7 <- lm(log(price) ~ table + x + clarity + cut, data = diamonds_sample)
# summary(test_model_7)
```

```{r Part 2.3, echo = T}
# The 1st model I was happy with 
test_model_4 <- lm(log(price) ~ table + x + clarity, data = diamonds_sample)

# The 2nd model I was happy with 
test_model_7 <- lm(log(price) ~ table + x + clarity + cut, data = diamonds_sample)
```

After realizing that my best model would come from the transformation of the price variable, I experimented with around 
7 different models to try and find the best one. After all of them I ended up with two models that I was pretty happy with.
The models were extremely close to each other when it came to their R-Squared values with 1 being 0.8696 and the second one
being 0.8697. At this point I can say that the model has multicolinearity, because of how lowly it originally aligned with 
the first two variables to now how it is a good model because of the additional variables added. 

In this part I found it interesting that with the two models I ended up choosing that their R-Squared values were so
incredibly close to each other. I also thought it was interesting that although the first model was just barely lower it had
one less variable than my second one. I would have thought that by adding the cut varibale to the model it would have done a
little bit more to effect the model, but in this case it didn't. 

## Part 3 - Goal

```{r Part 3, echo = T, results = T}
test_model_4 <- lm(log(price) ~ table + x + clarity, data = diamonds_sample)
summary(test_model_4)

test_model_7 <- lm(log(price) ~ table + x + clarity + cut, data = diamonds_sample)
summary(test_model_7)
```

Coming down to our last two models we can see that these are the same two that we ended up coming to a conclusion with at the
end of part 2. As we can see the first model looking at price, is made up of the variables table, x, and clarity. Then moving
onto the second model, it uses the variables table, x, clarity, and cut. While we add another variable to our second model, 
we can see that the estimates of the coefficients don't differentiate too much and are still relatively close to each other
when comparing the summarizes side by side. This shows how the models similarly and is a reason why the R-Squared values are
so close to each other. I think its also interesting to note that while we did add the variable, cut, to the second model, 
the summary doesn't show it to be significant as their P-values are too high and they don't have any signifigance stars next
to them in the summary.

```{r Part 3.1, echo = T, results = T}
AIC(test_model_4)
AIC(test_model_7)
BIC(test_model_4)
BIC(test_model_7)

final_model <- lm(log(price) ~ table + x + clarity, data = diamonds_sample)
```

Here I used decided to use both, the AIC and BIC to see which model was better and was interested how different the results 
would be or be close to the same thing. As we can see both of the tests came to the conclusion that the first model, 
test_model_4, was the better model. In the AIC and BIC, we see that they display a lower value than that of the 2nd model, 
indicating that it is a better model. 

```{r Part 3.2, echo = T, results = T}
x_comb<- data.frame(table = 56, x = 6.1, clarity = "VVS2")

ci_mean_log <- predict(final_model, x_comb, interval = "confidence")
pi_future_log <- predict(final_model, x_comb, interval = "prediction")

ci_mean_adj <- exp(ci_mean_log)
pi_future_adj <- exp(pi_future_log)

print(ci_mean_adj)
print(pi_future_adj)
```

Finally finishing the report, we can see a test I did of the model using the x values I manually inputted into the model. A
little note, I did have to adjust the intervals to account for the fact that I had to transform the price earlier in the 
report. Going back to the test, I used a value of 56 for table, 6.1 for x, and the clarity was categorized as VVS2. With
these value for the observation I got a confidence for the mean predicted value to be between $3559.24 and \$4491.13. Looking
at the predicted interval for the future predicted value, I got the value to be between $1870.91 and \$ 8543.95. Looking at
these ranges it is clear that there is a lot of work that could be done to the model in order to get a more refined interval
for both the pi and ci. At the end of the day it had to do with me randomly picking variables at the start, if I had looked
closer into each variable at the start of the experiment I could have created a more accurate model. However, being that the 
varibales I chose to make a model with were at random I felt that there was at least some direction with the model and 
transforming the price variable certainly played a big role. 